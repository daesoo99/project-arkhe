# Project Arkhē - Claude 작업 로그

## 최근 업데이트 (2025-08-08)

### 1. 정답 판별 로직 강화 ✅ 완료
- **구현**: `src/utils/scorers.py` - 태스크 타입별 전문 채점기
- **6가지 채점기**:
  - `score_fact`: 숫자 오차 허용(5%), 정확한 텍스트 매칭
  - `score_reason`: 키워드 체크리스트 기반 추론 채점
  - `score_summary`: ROUGE-L 근사 계산
  - `score_format`: JSON 스키마 검증
  - `score_code`: 문법/구조 검사 (exec 금지)
  - `score_korean`: 한국어 특화 유사도 계산
- **통합**: `experiments/bench_simple.py`에서 활용
- **출력**: CSV에 `score_method`, `score_details` 컬럼 추가

### 2. 오케스트레이터 MVP 연결 ✅ 완료
- **파이프라인 시스템**: `src/orchestrator/pipeline.py`
  - `Pipeline` 클래스: 멀티에이전트 파이프라인 실행기
  - `PipelineBuilder`: 3가지 패턴 지원
    - `create_single_agent`: 단일 에이전트
    - `create_multi_independent`: 독립 멀티에이전트 (다수결)
    - `create_sequential_refinement`: 순차적 개선 파이프라인
  - 집계 전략: MAJORITY_VOTE, FIRST_VALID, CONSENSUS

- **LLM 통합 인터페이스**: `src/llm/simple_llm.py`
  - `LLM` 추상 클래스 - 통일된 `generate()` 인터페이스
  - `OllamaLLM`, `OpenAILLM`, `AnthropicLLM` 구현
  - `create_llm_auto()` - 모델 ID로 자동 프로바이더 감지

### 3. 비용/지연 스코어 통합 - 경제적 지능 비교 ✅ 완료
- **경제적 지능 메트릭**: `EconomicIntelligenceMetrics` 클래스
  - 비용 점수 = α*지연시간 + β*계산비용 (α=0.3, β=0.7)
  - 모델별 추정 비용: `gemma:2b(1.0) < phi3:mini(1.2) < mistral:7b(3.5) < llama3:8b(4.0)`
  - 종합 점수: 비용효율성(40%) + 속도(30%) + 안정성(30%)

### 4. 통합 테스트에서 파이프라인 AB 비교 구현 ✅ 완료
- **통합 테스터**: `experiments/integrated_test.py`
- **AB 비교 결과**:
  ```
  A-Single (gemma:2b 단일): 
  - 비용점수: 3.547, 시간: 3570ms, 종합점수: 0.454

  B-Double (gemma:2b 2개):
  - 비용점수: 14.047, 시간: 14048ms, 종합점수: 0.347
  ```
- **자동 리포트 생성**: 비용효율성, 속도, 안정성 순위 + 종합 점수

## 핵심 발견 및 인사이트

### 경제적 지능 검증
- **단일 에이전트**가 동일 모델 멀티에이전트보다 **4배 효율적**
- **멀티에이전트의 가치**: 다양성 확보하지만 비용 대비 효율성은 낮음
- **다음 단계**: 경량 모델(qwen2:0.5b) + 고급 판정(llama3:8b) 파이프라인으로 진짜 경제적 지능 입증 필요

### 기술적 성과
1. **모듈화된 아키텍처**: 파이프라인, 채점기, LLM 인터페이스 분리
2. **확장 가능한 설계**: 새로운 채점기, 집계 전략, LLM 프로바이더 쉽게 추가
3. **실용적 메트릭**: 단순 정확도가 아닌 경제적 효율성 중심 평가

## 경제적 지능 실험 설계 (핵심 업데이트)

### 기본 공식
**총 실험군 공식**:
```
실험군 ≈ (초안 단계 선택지 × 샘플 수) × (검토 단계 선택지 × 샘플 수) × (판정 단계 선택지) × (프로모션 정책 수)
```

**비용 모델**:
```
총비용 = 0.8×n₁ + 1.0×n₂ + 4.0×n₃
n₁=초안 호출 수(qwen2:0.5b), n₂=검토 호출 수(gemma:2b), n₃=판정 호출 수(llama3:8b)
```

**예시**:
- 3단계(1-1-1회): `0.8 + 1.0 + 4.0 = 5.8`
- 초안 3안+판정: `0.8×3 + 1.0 + 4.0 = 7.4`

### A. 최소 세트 (6개) - 빠른 결론용
1. **Baseline–High**: `llama3:8b` 단독
2. **Baseline–Mid×3**: `gemma:2b` 3개 self-consistency  
3. **3-Stage(1-1-1)**: `qwen2:0.5b → gemma:2b → llama3:8b`
4. **3-Stage(3-1-1)**: `qwen2:0.5b×3 → gemma:2b → llama3:8b`
5. **엄격판정**: 판정 프롬프트에 포맷/근거 강제
6. **완화판정**: 판정 온도↓·길이↑로 리콜 우선

### B. 표준 세트 (12개) - 연구 결론용
위 6개 + 추가 6개:
7. **초안 모델 교체**: `phi3:mini → gemma:2b → llama3:8b`
8. **검토 모델 강화**: `qwen2:0.5b → mistral:7b → llama3:8b`
9. **Top-1 승격**: 초안 3안+엔트로피 상위 1개만 승격
10. **합의 요약**: 초안 3안 합의 요약 후 승격
11. **검토 2안**: `gemma:2b×2` 다중 리뷰 후 판정
12. **2-Stage**: `qwen2:0.5b → llama3:8b` (중간 생략)

### C. 확장 세트 (18개) - 논문화용
표준 12개 + 추가 6개:
13. **프로모션 20%**: 엔트로피 상위 20%만 llama3:8b 승격
14. **프로모션 40%**: 엔트로피 상위 40% 승격
15. **질문 슬롯**: 검토단계가 초안에 질의 1회 허용
16. **코드 전용**: `codellama:7b` 검토/판정 투입
17. **장문 전용**: `mistral:7b` vs `llama3:8b` 판정 비교
18. **온도 스위프**: 초안 T=0.0 vs 0.2 (일관성 vs 다양성)

### 실험 가이드라인
- **24개 초과 금지**: 실험당 10-15분이어도 하루가 소모됨
- **태스크별 층화**: (지식·추론·형식·코드) 4개 묶음으로 교란 제거
- **시드 3회**: 각 실험군 신뢰구간 확보
- **비용 캡**: 평균 비용 ≤ 7.0에서 Pareto 프론티어 도출

### 핵심 메트릭 수집
- **성능 메트릭**: `first_token_ms`, `total_ms`, `tok_per_s`
- **품질 메트릭**: 형식 실패율, 거절율(refusal pattern)
- **경제 메트릭**: 비용 효율성, Shannon Entropy 기반 프로모션 결정

## 다음 단계 (TODO)

### 🎯 즉시 구현 (Phase 1)
1. **3단계 스마트 파이프라인 구현**: `qwen2:0.5b → gemma:2b → llama3:8b`
2. **프로모션 정책 시스템**: 엔트로피 기반 적응적 승격
3. **표준 12개 실험군 자동화**: Pareto 프론티어 도출 시스템

### 🔬 향후 연구 확장 (Phase 2-3)

#### Phase 2: 정보 이론 기반 측정
- **Shannon Entropy 변화 추적**: 초안→검토→판정 단계별 정보 압축률 분석
- **정보 비대칭 지수**: 부분 정보(50%, 70%, 90%) 제공 시 성능 임계점 측정
- **채널 노이즈 주입**: 의도적 정보 손실 시 품질 하락폭 정량화
- **정보 전파 속도**: 에이전트 간 교환 라운드별 수렴 패턴 분석

#### Phase 3: 멀티에이전트 상호작용 연구
- **역할 분리형 실험**: Agent A(발굴)→B(분석)→C(판단) 정보 손실 패턴
- **중복 검증 구조**: 독립 판단 후 합의 과정의 정보 효율성
- **비용-정보 효율 프론티어**: 기존 "비용 vs 정확도"를 "비용 vs 정보 보존율"로 확장
- **지식 축적형 시나리오**: 이전 결과가 다음 질문에 미치는 누적 효과
- **토큰 제한 실험**: 256/512 토큰 상한에서의 정보량 vs 품질 trade-off

**목표**: 단순 벤치마크를 넘어 **"정보 이론 + 멀티에이전트 시스템"** 융합 연구 분야 개척

## 파일 구조
```
src/
├── orchestrator/
│   └── pipeline.py          # 파이프라인 오케스트레이터
├── llm/
│   ├── llm_interface.py     # 기존 LLM 인터페이스
│   └── simple_llm.py        # 새로운 통일된 LLM 클래스들
└── utils/
    └── scorers.py           # 태스크별 채점기 시스템

experiments/
├── bench_simple.py          # 강화된 채점 시스템 적용
└── integrated_test.py       # 파이프라인 AB 비교 테스터
```

## 실행 방법
```bash
# 강화된 채점 시스템 테스트
python experiments/bench_simple.py --limit 3

# 파이프라인 경제적 지능 비교
python experiments/integrated_test.py
```