#!/usr/bin/env python3
"""
Project ArkhÄ“ - Entropy Balanced Pipeline
Shannon Entropy ì´ë¡ ì„ í™œìš©í•œ ê· í˜•ì¡íŒ Multi-Agent íŒŒì´í”„ë¼ì¸
"""

import sys
from pathlib import Path

# Add src to path  
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from llm.simple_llm import create_llm_auto
from utils.information_theory import ShannonEntropyAnalyzer

class EntropyBalancedPipeline:
    """Shannon Entropy ê· í˜•ì„ ë§ì¶˜ ìµœì í™”ëœ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, llm_factory):
        self.llm_factory = llm_factory
        self.analyzer = ShannonEntropyAnalyzer()
        
        # ìµœì  ì—”íŠ¸ë¡œí”¼ ë²”ìœ„ (ì‹¤í—˜ì ìœ¼ë¡œ ë„ì¶œ)
        self.target_entropy_ranges = {
            "draft": (2.0, 4.0),      # ë‹¤ì–‘í•˜ì§€ë§Œ ë„ˆë¬´ ê³¼í•˜ì§€ ì•Šê²Œ
            "review": (3.0, 5.0),     # ì¢€ ë” í’ë¶€í•˜ê²Œ  
            "judge": (3.5, 6.0)       # ìµœì¢… ê²°ì •ì„ ìœ„í•œ ì ì • ë³µì¡ë„
        }
    
    def entropy_controlled_draft(self, prompt: str) -> str:
        """ì—”íŠ¸ë¡œí”¼ ì œì–´ëœ Draft ë‹¨ê³„"""
        
        # ì´ˆê¸° Draft ìƒì„±
        llm = self.llm_factory("qwen2:7b")  # ë” í° ëª¨ë¸ë¡œ í’ˆì§ˆ í–¥ìƒ
        
        draft_prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ í•µì‹¬ì ì´ë©´ì„œë„ ë‹¤ê°ë„ì˜ ì´ˆì•ˆì„ ì‘ì„±í•˜ì„¸ìš”:

{prompt}

ìš”êµ¬ì‚¬í•­:
- 3-4ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ê´€ì ì„ ê°„ê²°í•˜ê²Œ ì œì‹œ
- ê° ê´€ì ë§ˆë‹¤ 2-3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…
- ë„ˆë¬´ ë°˜ë³µì ì´ì§€ ì•Šë„ë¡ ë‹¤ì–‘í•œ í‘œí˜„ ì‚¬ìš©
"""
        
        response_dict = llm.generate(draft_prompt)
        draft = response_dict.get('response', str(response_dict)) if isinstance(response_dict, dict) else str(response_dict)
        
        # ì—”íŠ¸ë¡œí”¼ ì²´í¬ ë° ì¡°ì •
        current_entropy = self.analyzer.calculate_shannon_entropy(draft)
        target_min, target_max = self.target_entropy_ranges["draft"]
        
        if current_entropy < target_min:
            # ì—”íŠ¸ë¡œí”¼ ë„ˆë¬´ ë‚®ìŒ - ë‹¤ì–‘ì„± ì¶”ê°€
            enhancement_prompt = f"""
ë‹¤ìŒ ì´ˆì•ˆì„ ë” ë‹¤ì–‘í•˜ê³  ì°½ì˜ì ìœ¼ë¡œ í™•ì¥í•˜ì„¸ìš”:

{draft}

ì¶”ê°€ë¡œ ê³ ë ¤í•  ê´€ì :
- ë‹¤ë¥¸ ì—…ê³„/ë¶„ì•¼ì˜ ìœ ì‚¬ ì‚¬ë¡€
- ì˜ˆìƒì¹˜ ëª»í•œ ë¶€ì‘ìš©ì´ë‚˜ ê¸°íšŒ
- í˜ì‹ ì ì´ê±°ë‚˜ ë¹„ì „í†µì  ì ‘ê·¼ë²•
"""
            enhanced_dict = llm.generate(enhancement_prompt)
            draft = enhanced_dict.get('response', str(enhanced_dict)) if isinstance(enhanced_dict, dict) else str(enhanced_dict)
            
        elif current_entropy > target_max:
            # ì—”íŠ¸ë¡œí”¼ ë„ˆë¬´ ë†’ìŒ - í•µì‹¬ ì •ë¦¬
            refinement_prompt = f"""
ë‹¤ìŒ ì´ˆì•ˆì˜ í•µì‹¬ ë‚´ìš©ì„ ì •ë¦¬í•˜ì—¬ ë” ì§‘ì¤‘ëœ í˜•íƒœë¡œ ì¬ì‘ì„±í•˜ì„¸ìš”:

{draft}

ìš”êµ¬ì‚¬í•­:
- ê°€ì¥ ì¤‘ìš”í•œ 3ê°œ í¬ì¸íŠ¸ë§Œ ì„ ë³„
- ì¤‘ë³µë˜ëŠ” ë‚´ìš© ì œê±°  
- ëª…í™•í•˜ê³  ê°„ê²°í•œ í‘œí˜„ ì‚¬ìš©
"""
            refined_dict = llm.generate(refinement_prompt)
            draft = refined_dict.get('response', str(refined_dict)) if isinstance(refined_dict, dict) else str(refined_dict)
        
        return draft
    
    def entropy_controlled_review(self, prompt: str, draft: str) -> str:
        """ì—”íŠ¸ë¡œí”¼ ì œì–´ëœ Review ë‹¨ê³„"""
        
        llm = self.llm_factory("qwen2:7b")
        
        review_prompt = f"""
ë‹¤ìŒ ì´ˆì•ˆì„ ê²€í† í•˜ê³  ê· í˜•ì¡íŒ ê°œì„ ì•ˆì„ ì œì‹œí•˜ì„¸ìš”:

ì›ë˜ ì§ˆë¬¸: {prompt}
ì´ˆì•ˆ: {draft}

ê²€í†  ê¸°ì¤€:
1. ëˆ„ë½ëœ ì¤‘ìš”í•œ ê´€ì ì´ ìˆëŠ”ê°€?
2. ë…¼ë¦¬ì  ì¼ê´€ì„±ì€ ì¶©ë¶„í•œê°€?  
3. ì‹¤ìš©ì„±ê³¼ ì°½ì˜ì„±ì˜ ê· í˜•ì€ ì ì ˆí•œê°€?

ê°œì„ ëœ ë‹µë³€ì„ ì‘ì„±í•˜ë˜, ì§€ë‚˜ì¹˜ê²Œ ë³µì¡í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.
"""
        
        response_dict = llm.generate(review_prompt)
        review = response_dict.get('response', str(response_dict)) if isinstance(response_dict, dict) else str(response_dict)
        
        # ì—”íŠ¸ë¡œí”¼ ê· í˜• ì²´í¬
        current_entropy = self.analyzer.calculate_shannon_entropy(review)
        target_min, target_max = self.target_entropy_ranges["review"]
        
        # Review ë‹¨ê³„ì—ì„œëŠ” ì ë‹¹í•œ ë³µì¡ë„ ìœ ì§€
        if current_entropy < target_min or current_entropy > target_max:
            balance_prompt = f"""
ë‹¤ìŒ ë‚´ìš©ì„ ì ì ˆí•œ ë³µì¡ë„ë¡œ ì¡°ì •í•˜ì„¸ìš”:

{review}

ëª©í‘œ: ë„ˆë¬´ ë‹¨ìˆœí•˜ì§€ë„, ë„ˆë¬´ ë³µì¡í•˜ì§€ë„ ì•Šì€ ê· í˜•ì¡íŒ ë¶„ì„
- í•µì‹¬ ì•„ì´ë””ì–´ëŠ” ìœ ì§€
- ì ë‹¹í•œ ì„¸ë¶€ì‚¬í•­ í¬í•¨
- ëª…í™•í•œ êµ¬ì¡°ì™€ íë¦„
"""
            balanced_dict = llm.generate(balance_prompt)
            review = balanced_dict.get('response', str(balanced_dict)) if isinstance(balanced_dict, dict) else str(balanced_dict)
        
        return review
    
    def entropy_controlled_judge(self, prompt: str, draft: str, review: str) -> str:
        """ì—”íŠ¸ë¡œí”¼ ì œì–´ëœ Judge ë‹¨ê³„"""
        
        llm = self.llm_factory("llama3:8b")  # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
        
        judge_prompt = f"""
ë‹¤ìŒ ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ìµœì ì˜ ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”:

ì§ˆë¬¸: {prompt}
ì´ˆì•ˆ: {draft}
ê²€í† ì˜ê²¬: {review}

ìµœì¢… ë‹µë³€ ì‘ì„± ì§€ì¹¨:
- ì´ˆì•ˆê³¼ ê²€í† ì˜ê²¬ì˜ ì¥ì ì„ ëª¨ë‘ í™œìš©
- ëª…í™•í•˜ê³  ì‹¤ìš©ì ì¸ ê²°ë¡  ë„ì¶œ
- ì ì ˆí•œ ê¹Šì´ì™€ í­ì„ ê°–ì¶˜ ì¢…í•©ì  ë‹µë³€
- ë…ìê°€ ì´í•´í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€

ê· í˜•ì¡íŒ ìµœê³  í’ˆì§ˆì˜ ë‹µë³€ì„ ì œì‹œí•˜ì„¸ìš”.
"""
        
        response_dict = llm.generate(judge_prompt)
        final = response_dict.get('response', str(response_dict)) if isinstance(response_dict, dict) else str(response_dict)
        
        return final
    
    def execute_balanced_pipeline(self, prompt: str):
        """ê· í˜•ì¡íŒ ì—”íŠ¸ë¡œí”¼ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        
        print(f"Executing Entropy-Balanced Pipeline...")
        print(f"Question: {prompt[:60]}...")
        
        # Stage 1: Entropy-Controlled Draft
        print("  Stage 1: Generating balanced draft...")
        draft = self.entropy_controlled_draft(prompt)
        draft_entropy = self.analyzer.calculate_shannon_entropy(draft)
        print(f"    Draft entropy: {draft_entropy:.2f}")
        
        # Stage 2: Entropy-Controlled Review  
        print("  Stage 2: Balanced review...")
        review = self.entropy_controlled_review(prompt, draft)
        review_entropy = self.analyzer.calculate_shannon_entropy(review)
        print(f"    Review entropy: {review_entropy:.2f}")
        
        # Stage 3: Entropy-Controlled Judge
        print("  Stage 3: Final balanced judgment...")
        final = self.entropy_controlled_judge(prompt, draft, review)
        final_entropy = self.analyzer.calculate_shannon_entropy(final)
        print(f"    Final entropy: {final_entropy:.2f}")
        
        return {
            "prompt": prompt,
            "draft": draft,
            "review": review, 
            "final": final,
            "entropy_progression": [draft_entropy, review_entropy, final_entropy],
            "pipeline_type": "entropy_balanced"
        }

def test_entropy_balanced_pipeline():
    """ì—”íŠ¸ë¡œí”¼ ê· í˜• íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    
    llm_factory = create_llm_auto
    pipeline = EntropyBalancedPipeline(llm_factory)
    
    # í…ŒìŠ¤íŠ¸ ë¬¸ì œë“¤
    test_questions = [
        "ë¯¸ë˜ ë„ì‹œì˜ êµí†µ ì²´ì¦ì„ í•´ê²°í•  ìˆ˜ ìˆëŠ” í˜ì‹ ì  ë°©ë²•ì€?",
        "AIì™€ ì¸ê°„ì´ í˜‘ì—…í•˜ëŠ” ì´ìƒì ì¸ ì§ì¥ í™˜ê²½ì„ ì–´ë–»ê²Œ ë§Œë“¤ ìˆ˜ ìˆì„ê¹Œ?",
        "ê¸°í›„ë³€í™”ì— ëŒ€ì‘í•˜ê¸° ìœ„í•œ ê°œì¸ ì°¨ì›ì˜ ì‹¤ì²œ ë°©ì•ˆì€?"
    ]
    
    results = []
    
    for question in test_questions:
        print(f"\n{'='*60}")
        result = pipeline.execute_balanced_pipeline(question)
        results.append(result)
        
        print(f"\nEntropy Progression:")
        entropies = result["entropy_progression"]
        print(f"  Draft â†’ Review â†’ Final: {entropies[0]:.2f} â†’ {entropies[1]:.2f} â†’ {entropies[2]:.2f}")
        
        # ì—”íŠ¸ë¡œí”¼ ì•ˆì •ì„± ì²´í¬
        if 3.0 <= entropies[2] <= 6.0:
            print(f"  âœ“ Final entropy in optimal range")
        else:
            print(f"  âš  Final entropy outside optimal range")
        
        print(f"\nFinal Answer Preview:")
        print(f"  {result['final'][:200]}...")
    
    print(f"\n{'='*60}")
    print("Entropy-Balanced Pipeline Test Complete")
    
    # ì „ì²´ ì—”íŠ¸ë¡œí”¼ íŒ¨í„´ ë¶„ì„
    all_final_entropies = [r["entropy_progression"][2] for r in results]
    avg_final_entropy = sum(all_final_entropies) / len(all_final_entropies)
    
    print(f"\nOverall Results:")
    print(f"  Average final entropy: {avg_final_entropy:.2f}")
    print(f"  Entropy consistency: {min(all_final_entropies):.2f} - {max(all_final_entropies):.2f}")
    
    if 3.5 <= avg_final_entropy <= 5.5:
        print(f"  ğŸ¯ Optimal entropy balance achieved!")
        print(f"  ğŸ’¡ This pipeline should provide rich but focused responses")
    else:
        print(f"  ğŸ”§ Entropy balance needs adjustment")

if __name__ == "__main__":
    test_entropy_balanced_pipeline()