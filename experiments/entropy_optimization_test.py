#!/usr/bin/env python3
"""
Project ArkhÄ“ - Shannon Entropy Optimization Test
ì •ë³´ ì´ë¡  ê¸°ë°˜ Multi-Agent íŒŒì´í”„ë¼ì¸ ìµœì í™” ì‹¤í—˜
"""

import json
import time
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from llm.simple_llm import create_llm_auto
from orchestrator.pipeline import run_3stage_with_context
from utils.information_theory import ShannonEntropyAnalyzer, EntropyBasedOptimizer
from utils.scorers import score_task

def run_entropy_tracked_pipeline(prompt: str, llm_factory, analyzer: ShannonEntropyAnalyzer):
    """ì—”íŠ¸ë¡œí”¼ ì¶”ì ì´ í¬í•¨ëœ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    
    start_time = time.time()
    
    # ìˆ˜ë™ìœ¼ë¡œ ê° ë‹¨ê³„ ì‹¤í–‰í•˜ë©° ì—”íŠ¸ë¡œí”¼ ì¶”ì 
    llm_draft = llm_factory("qwen2:0.5b")  
    llm_review = llm_factory("gemma:2b")
    llm_judge = llm_factory("llama3:8b")
    
    # Stage 1: Draft
    draft_prompt = f"ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ì´ˆì•ˆì„ ì‘ì„±í•˜ì„¸ìš”: {prompt}"
    draft_response_dict = llm_draft.generate(draft_prompt)
    draft_response = draft_response_dict.get('response', str(draft_response_dict)) if isinstance(draft_response_dict, dict) else str(draft_response_dict)
    
    # ì—”íŠ¸ë¡œí”¼ ì¶”ì : ì…ë ¥ â†’ Draft
    flow1 = analyzer.track_information_flow("Draft", prompt, draft_response)
    
    # Stage 2: Review  
    review_prompt = f"""
ì´ì „ ì´ˆì•ˆì„ ê²€í† í•˜ê³  ê°œì„ í•˜ì„¸ìš”:

ì›ë˜ ì§ˆë¬¸: {prompt}
ì´ˆì•ˆ: {draft_response}

ê°œì„ ëœ ë‹µë³€ì„ ì œì‹œí•˜ì„¸ìš”:
"""
    review_response_dict = llm_review.generate(review_prompt)
    review_response = review_response_dict.get('response', str(review_response_dict)) if isinstance(review_response_dict, dict) else str(review_response_dict)
    
    # ì—”íŠ¸ë¡œí”¼ ì¶”ì : Draft â†’ Review
    flow2 = analyzer.track_information_flow("Review", draft_response, review_response)
    
    # Stage 3: Judge
    judge_prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ìµœì¢… ë‹µë³€ì„ ì œì‹œí•˜ì„¸ìš”:

ì§ˆë¬¸: {prompt}
ì´ˆì•ˆ: {draft_response}
ê²€í†  ì˜ê²¬: {review_response}

ìœ„ ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ìµœê³  í’ˆì§ˆì˜ ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”:
"""
    judge_response_dict = llm_judge.generate(judge_prompt)
    judge_response = judge_response_dict.get('response', str(judge_response_dict)) if isinstance(judge_response_dict, dict) else str(judge_response_dict)
    
    # ì—”íŠ¸ë¡œí”¼ ì¶”ì : Review â†’ Judge
    flow3 = analyzer.track_information_flow("Judge", review_response, judge_response)
    
    end_time = time.time()
    
    return {
        "prompt": prompt,
        "draft": draft_response,
        "review": review_response, 
        "final": judge_response,
        "execution_time": end_time - start_time,
        "entropy_flows": [flow1, flow2, flow3],
        "tokens": len(prompt.split()) + len(draft_response.split()) + len(review_response.split()) + len(judge_response.split())
    }

def run_single_model_baseline(prompt: str, llm_factory, analyzer: ShannonEntropyAnalyzer):
    """Single ëª¨ë¸ ê¸°ì¤€ ì‹¤í—˜ (ì—”íŠ¸ë¡œí”¼ ì¶”ì  í¬í•¨)"""
    
    start_time = time.time()
    
    llm = llm_factory("llama3:8b")
    response_dict = llm.generate(prompt)
    response = response_dict.get('response', str(response_dict)) if isinstance(response_dict, dict) else str(response_dict)
    
    end_time = time.time()
    
    # ì—”íŠ¸ë¡œí”¼ ì¶”ì : ì…ë ¥ â†’ ì¶œë ¥
    flow = analyzer.track_information_flow("Single", prompt, response)
    
    return {
        "prompt": prompt,
        "final": response,
        "execution_time": end_time - start_time,
        "entropy_flows": [flow],
        "tokens": len(prompt.split()) + len(response.split())
    }

def analyze_entropy_performance(multi_result, single_result, analyzer: ShannonEntropyAnalyzer):
    """ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ ì„±ëŠ¥ ë¶„ì„"""
    
    # Multi-Agent íŒŒì´í”„ë¼ì¸ ë¶„ì„
    multi_analysis = analyzer.analyze_pipeline_efficiency()
    analyzer.stage_history.clear()  # ê¸°ë¡ ì´ˆê¸°í™”
    
    # Single Model ë¶„ì„  
    single_analysis = analyzer.analyze_pipeline_efficiency()
    analyzer.stage_history.clear()
    
    # ë¹„êµ ë©”íŠ¸ë¦­
    comparison = {
        "information_preservation": {
            "multi": multi_analysis.get("information_preservation_rate", 0),
            "single": single_analysis.get("information_preservation_rate", 0)
        },
        "average_efficiency": {
            "multi": multi_analysis.get("average_stage_efficiency", 0),
            "single": single_analysis.get("average_stage_efficiency", 0)
        },
        "final_entropy": {
            "multi": multi_analysis.get("final_entropy", 0),
            "single": single_analysis.get("final_entropy", 0)
        },
        "information_gain": {
            "multi": multi_analysis.get("total_information_gain", 0),
            "single": single_analysis.get("total_information_gain", 0)
        }
    }
    
    return {
        "multi_pipeline_analysis": multi_analysis,
        "single_analysis": single_analysis,
        "comparison": comparison
    }

def main():
    """Shannon Entropy ìµœì í™” ì‹¤í—˜ ë©”ì¸"""
    print("Shannon Entropy Optimization Test: Information Theory Meets Multi-Agent")
    print("=" * 80)
    
    # í…ŒìŠ¤íŠ¸ ë¬¸ì œë“¤ (ë‹¤ì–‘í•œ ë³µì¡ë„)
    test_problems = [
        {
            "id": "simple",
            "prompt": "íŒŒë¦¬ëŠ” ì–´ëŠ ë‚˜ë¼ì˜ ìˆ˜ë„ì¸ê°€ìš”?",
            "expected_complexity": 2.0,
            "answer": "í”„ë‘ìŠ¤"
        },
        {
            "id": "moderate", 
            "prompt": "ê¸°í›„ë³€í™” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ 3ê°€ì§€ í˜ì‹ ì  ë°©ë²•ì„ ì œì‹œí•˜ê³  ê°ê°ì˜ ì¥ë‹¨ì ì„ ì„¤ëª…í•˜ì‹œì˜¤.",
            "expected_complexity": 6.0,
            "answer": "ì¬ìƒì—ë„ˆì§€ ì „í™˜, íƒ„ì†Œí¬ì§‘ê¸°ìˆ , ë¼ì´í”„ìŠ¤íƒ€ì¼ ë³€í™”"
        },
        {
            "id": "creative",
            "prompt": "AIì™€ ì¸ê°„ì´ í˜‘ì—…í•˜ëŠ” 2050ë…„ ë¯¸ë˜ ì§ì¥ì˜ ëª¨ìŠµì„ ìƒìƒí•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ë¬˜ì‚¬í•˜ì‹œì˜¤.",
            "expected_complexity": 8.0,
            "answer": "ì°½ì˜ì  ìƒìƒë ¥ ê¸°ë°˜ ë¯¸ë˜ ì§ì¥ ì‹œë‚˜ë¦¬ì˜¤"
        }
    ]
    
    llm_factory = create_llm_auto
    results = []
    
    for i, problem in enumerate(test_problems):
        print(f"\n--- Entropy Test {i+1}: {problem['id'].upper()} ---")
        print(f"Problem: {problem['prompt'][:60]}...")
        print(f"Expected Complexity: {problem['expected_complexity']}")
        
        try:
            # Multi-Agent ì—”íŠ¸ë¡œí”¼ ì¶”ì  ì‹¤í—˜
            print("\\n  Running Multi-Agent with Entropy Tracking...")
            multi_analyzer = ShannonEntropyAnalyzer()
            multi_result = run_entropy_tracked_pipeline(problem['prompt'], llm_factory, multi_analyzer)
            
            # Single Model ê¸°ì¤€ ì‹¤í—˜
            print("  Running Single Model baseline...")
            single_analyzer = ShannonEntropyAnalyzer()
            single_result = run_single_model_baseline(problem['prompt'], llm_factory, single_analyzer)
            
            # ì—”íŠ¸ë¡œí”¼ ì„±ëŠ¥ ë¶„ì„
            entropy_analysis = analyze_entropy_performance(multi_result, single_result, multi_analyzer)
            
            # ì •í™•ë„ í‰ê°€
            multi_score = score_task("reason", problem["answer"], multi_result["final"])
            single_score = score_task("reason", problem["answer"], single_result["final"])
            
            result = {
                "problem": problem,
                "multi_result": multi_result,
                "single_result": single_result,
                "entropy_analysis": entropy_analysis,
                "accuracy": {
                    "multi": multi_score["score"],
                    "single": single_score["score"]
                }
            }
            results.append(result)
            
            # ì¤‘ê°„ ê²°ê³¼ ì¶œë ¥
            print(f"\\n  Information Flow Analysis:")
            
            # Multi-Agent ë‹¨ê³„ë³„ ì •ë³´ íë¦„
            print(f"    Multi-Agent Pipeline:")
            for flow in multi_result["entropy_flows"]:
                gain_symbol = "ğŸ“ˆ" if flow.information_gain > 0 else "ğŸ“‰" if flow.information_gain < -0.5 else "â¡ï¸"
                print(f"      {gain_symbol} {flow.stage_name}: {flow.input_entropy:.2f} â†’ {flow.output_entropy:.2f} (gain: {flow.information_gain:+.2f})")
            
            # Single Model ì •ë³´ íë¦„
            single_flow = single_result["entropy_flows"][0]
            single_symbol = "ğŸ“ˆ" if single_flow.information_gain > 0 else "ğŸ“‰" if single_flow.information_gain < -0.5 else "â¡ï¸"
            print(f"    Single Model:")
            print(f"      {single_symbol} {single_flow.stage_name}: {single_flow.input_entropy:.2f} â†’ {single_flow.output_entropy:.2f} (gain: {single_flow.information_gain:+.2f})")
            
            # ì„±ëŠ¥ ë¹„êµ
            comparison = entropy_analysis["comparison"]
            print(f"\\n  Performance Comparison:")
            print(f"    Information Preservation: Multi {comparison['information_preservation']['multi']:.2f} vs Single {comparison['information_preservation']['single']:.2f}")
            print(f"    Final Entropy: Multi {comparison['final_entropy']['multi']:.2f} vs Single {comparison['final_entropy']['single']:.2f}")
            print(f"    Accuracy: Multi {multi_score['score']:.2f} vs Single {single_score['score']:.2f}")
            print(f"    Time: Multi {multi_result['execution_time']:.1f}s vs Single {single_result['execution_time']:.1f}s")
            
            # ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ íŒì •
            if comparison['final_entropy']['multi'] > comparison['final_entropy']['single'] * 1.2:
                print(f"    ğŸ¯ Multi-Agent shows superior information richness!")
            elif comparison['information_preservation']['multi'] > comparison['information_preservation']['single']:
                print(f"    ğŸ“Š Multi-Agent preserves information better")
            else:
                print(f"    âš–ï¸ Mixed results - Single model more efficient")
                
        except Exception as e:
            print(f"    Error: {e}")
            continue
    
    # ì „ì²´ ë¶„ì„
    print("\\n" + "=" * 80)
    print("Overall Shannon Entropy Analysis")
    print("=" * 80)
    
    if results:
        # í‰ê·  ë©”íŠ¸ë¦­ ê³„ì‚°
        avg_multi_entropy = sum(r["entropy_analysis"]["comparison"]["final_entropy"]["multi"] for r in results) / len(results)
        avg_single_entropy = sum(r["entropy_analysis"]["comparison"]["final_entropy"]["single"] for r in results) / len(results)
        avg_multi_accuracy = sum(r["accuracy"]["multi"] for r in results) / len(results)
        avg_single_accuracy = sum(r["accuracy"]["single"] for r in results) / len(results)
        
        print(f"\\nOverall Information Theory Results:")
        print(f"  Average Final Entropy: Multi {avg_multi_entropy:.2f} vs Single {avg_single_entropy:.2f}")
        print(f"  Average Accuracy: Multi {avg_multi_accuracy:.2f} vs Single {avg_single_accuracy:.2f}")
        print(f"  Information Richness Ratio: {avg_multi_entropy / avg_single_entropy:.2f}x")
        
        # ê²°ë¡ 
        entropy_advantage = avg_multi_entropy / avg_single_entropy
        accuracy_advantage = avg_multi_accuracy / avg_single_accuracy
        
        print(f"\\nShannon Entropy Conclusion:")
        if entropy_advantage > 1.3 and accuracy_advantage > 0.9:
            print(f"  ğŸ“Š Multi-Agent excels in information richness!")
            print(f"  ğŸ¯ {((entropy_advantage-1)*100):.1f}% richer information content")
            print(f"  ğŸ’¡ Optimal for problems requiring diverse perspectives")
        elif entropy_advantage > 1.1:
            print(f"  ğŸ“ˆ Multi-Agent shows information advantages")
            print(f"  ğŸ” Better for complex, open-ended problems")
        else:
            print(f"  ğŸ“‰ Single model more information-efficient")
            print(f"  âš¡ Better for straightforward, focused tasks")
        
        # ìµœì í™” ì œì•ˆ
        print(f"\\nOptimization Suggestions:")
        optimizer = EntropyBasedOptimizer(ShannonEntropyAnalyzer())
        
        for result in results:
            problem_id = result["problem"]["id"]
            complexity = result["problem"]["expected_complexity"]
            optimal_config = optimizer.calculate_optimal_model_allocation(complexity)
            print(f"  {problem_id.upper()}: {optimal_config}")
        
        # ê²°ê³¼ ì €ì¥
        timestamp = int(time.time())
        output_file = Path(__file__).parent.parent / "results" / f"entropy_optimization_results_{timestamp}.json"
        output_file.parent.mkdir(exist_ok=True)
        
        # JSON ì§ë ¬í™”ë¥¼ ìœ„í•´ ê²°ê³¼ ì •ë¦¬
        json_results = []
        for result in results:
            json_result = {
                "problem": result["problem"],
                "multi_accuracy": result["accuracy"]["multi"],
                "single_accuracy": result["accuracy"]["single"],
                "multi_entropy": result["entropy_analysis"]["comparison"]["final_entropy"]["multi"],
                "single_entropy": result["entropy_analysis"]["comparison"]["final_entropy"]["single"],
                "multi_time": result["multi_result"]["execution_time"],
                "single_time": result["single_result"]["execution_time"]
            }
            json_results.append(json_result)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                "experiment": "shannon_entropy_optimization",
                "timestamp": timestamp,
                "results": json_results,
                "summary": {
                    "avg_entropy_advantage": entropy_advantage,
                    "avg_accuracy_advantage": accuracy_advantage,
                    "information_richness_improvement": (entropy_advantage - 1) * 100
                }
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\\nResults saved: {output_file}")

if __name__ == "__main__":
    main()